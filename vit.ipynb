{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification, TrainingArguments, Trainer, ViTConfig\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Set device to CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the main dataframe\n",
    "train_df_main = pd.read_csv('train_df.csv')\n",
    "all_image_paths = {os.path.basename(x): x for x in glob(os.path.join('images*', '*', '*.png'))}\n",
    "train_df_main[\"FilePath\"] = train_df_main[\"Image Index\"].map(all_image_paths)\n",
    "train_df_main.drop(['No Finding'], axis=1, inplace=True)\n",
    "\n",
    "# Filter for only Cardiomegaly and Effusion\n",
    "selected_labels = ['Cardiomegaly', 'Effusion']\n",
    "train_df_main = train_df_main[['Image Index', 'FilePath'] + selected_labels]\n",
    "train_df_main = train_df_main[(train_df_main[selected_labels] == 1).any(axis=1)]\n",
    "\n",
    "# Function to get a subset of the data with specific number of images per label\n",
    "def create_label_subset(df, labels, num_samples=100):\n",
    "    subsets = []\n",
    "    for label in labels:\n",
    "        label_subset = df[df[label] == 1].sample(n=num_samples, random_state=42)\n",
    "        subsets.append(label_subset)\n",
    "    subset_df = pd.concat(subsets).drop_duplicates().reset_index(drop=True)\n",
    "    return subset_df\n",
    "\n",
    "# Create subset\n",
    "subset_df = create_label_subset(train_df_main, selected_labels, num_samples=100)\n",
    "\n",
    "# Check if the subset was created correctly\n",
    "print(subset_df.head())\n",
    "print(f\"Total images in subset: {len(subset_df)}\")\n",
    "\n",
    "# Specify the directory where you want to save the file\n",
    "output_directory = './output_directory'\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = os.path.join(output_directory, 'subset_df_new.csv')\n",
    "\n",
    "# Save to a new CSV (optional)\n",
    "try:\n",
    "    subset_df.to_csv(output_file_path, index=False)\n",
    "    print(f\"Subset saved to {output_file_path}\")\n",
    "except PermissionError as e:\n",
    "    print(f\"PermissionError: {e}. Could not save the file at {output_file_path}\")\n",
    "\n",
    "# Define custom dataset for ViT\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, df, labels, transform=None):\n",
    "        self.df = df\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.image_paths = df['FilePath'].values\n",
    "        self.label_values = df[labels].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(self.label_values[idx], dtype=torch.float32)\n",
    "        return {\"pixel_values\": image, \"labels\": label}\n",
    "\n",
    "# Custom transform function\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "train_dataset = CustomImageDataset(subset_df, selected_labels, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Initialize the model from scratch\n",
    "config = ViTConfig(\n",
    "    hidden_size=768,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=12,\n",
    "    image_size=224,\n",
    "    patch_size=16,\n",
    "    num_labels=len(selected_labels)\n",
    ")\n",
    "model = ViTForImageClassification(config).to(device)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    warmup_steps=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    eval_steps=10,\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "        loss = torch.nn.BCEWithLogitsLoss()(outputs.logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def compute_metrics(self, p):\n",
    "        preds = torch.sigmoid(p.predictions).cpu().numpy()\n",
    "        labels = p.label_ids\n",
    "        preds = (preds > 0.5).astype(int)\n",
    "        accuracy = (preds == labels).mean()\n",
    "        return {\"accuracy\": accuracy}\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=train_dataset,  # Use train dataset for evaluation as placeholder\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained('./trained_model')\n",
    "\n",
    "# Evaluation on test set\n",
    "def evaluate_model(trainer, dataset):\n",
    "    trainer.model.eval()  # Set the model to evaluation mode\n",
    "    predictions, labels = [], []\n",
    "    for batch in DataLoader(dataset, batch_size=4):\n",
    "        inputs = {\"pixel_values\": batch[\"pixel_values\"].to(device)}\n",
    "        with torch.no_grad():\n",
    "            outputs = trainer.model(**inputs)\n",
    "        logits = outputs.logits.detach().cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        labels.append(batch[\"labels\"].numpy())\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    predictions = (predictions > 0.5).astype(int)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='macro')\n",
    "    return acc, f1\n",
    "\n",
    "# Create test dataset and evaluate\n",
    "test_dataset = CustomImageDataset(subset_df, selected_labels, transform=transform)\n",
    "accuracy, f1 = evaluate_model(trainer, test_dataset)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
